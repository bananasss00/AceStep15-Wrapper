import sys
import os
import tempfile
import torch
import torchaudio
import folder_paths
import hashlib
import json
import shutil
import glob
import comfy.utils

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

from acestep.handler import AceStepHandler
from acestep.llm_inference import LLMHandler
from acestep.inference import generate_music, GenerationParams, GenerationConfig, format_sample

# === –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô ===
ACESTEP_MODELS_DIR = os.path.join(folder_paths.models_dir, "acestep")
if not os.path.exists(ACESTEP_MODELS_DIR):
    os.makedirs(ACESTEP_MODELS_DIR)

# ============================================================================
# 1. –ó–∞–≥—Ä—É–∑—á–∏–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
# ============================================================================
class AceStepModelLoader:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "config_path": (["acestep-v15-turbo", "acestep-v15-base", "acestep-v15-sft"], {"default": "acestep-v15-turbo"}),
                "device": (["auto", "cuda", "mps", "cpu"], {"default": "auto"}),
                "init_llm": ("BOOLEAN", {"default": True, "label_on": "Yes", "label_off": "No"}),
                "lm_model_path": (["acestep-5Hz-lm-1.7B", "acestep-5Hz-lm-0.6B", "acestep-5Hz-lm-4B"], {"default": "acestep-5Hz-lm-1.7B"}),
                "lm_backend": (["vllm", "pt", "mlx"], {"default": "vllm"}),
                "use_flash_attention": ("BOOLEAN", {"default": True}),
                "offload_to_cpu": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("ACESTEP_MODEL",)
    RETURN_NAMES = ("model",)
    FUNCTION = "load_model"
    CATEGORY = "ACE-Step"

    def load_model(self, config_path, device, init_llm, lm_model_path, lm_backend, use_flash_attention, offload_to_cpu):
        print(f"[ACE-Step] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è. –¶–µ–ª–µ–≤–∞—è –ø–∞–ø–∫–∞ –º–æ–¥–µ–ª–µ–π: {ACESTEP_MODELS_DIR}")
        
        dit_handler = AceStepHandler()
        llm_handler = LLMHandler()

        dit_handler._get_project_root = lambda: ACESTEP_MODELS_DIR
        project_root = ACESTEP_MODELS_DIR

        status, enable_gen = dit_handler.initialize_service(
            project_root=project_root,
            config_path=config_path,
            device=device,
            use_flash_attention=use_flash_attention,
            compile_model=False,
            offload_to_cpu=offload_to_cpu,
            offload_dit_to_cpu=offload_to_cpu
        )

        if not enable_gen:
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DiT –º–æ–¥–µ–ª–∏: {status}")

        if init_llm:
            print(f"[ACE-Step] –ó–∞–≥—Ä—É–∑–∫–∞ LLM {lm_model_path}...")
            checkpoint_dir = os.path.join(project_root, "checkpoints")
            
            from acestep.model_downloader import ensure_lm_model
            try:
                ensure_lm_model(model_name=lm_model_path, checkpoints_dir=checkpoint_dir)
            except Exception as e:
                print(f"[ACE-Step] –û—à–∏–±–∫–∞ –∞–≤—Ç–æ-—Å–∫–∞—á–∏–≤–∞–Ω–∏—è LLM: {e}")

            lm_status, lm_success = llm_handler.initialize(
                checkpoint_dir=checkpoint_dir,
                lm_model_path=lm_model_path,
                backend=lm_backend,
                device=device,
                offload_to_cpu=offload_to_cpu,
            )
            if not lm_success:
                print(f"[ACE-Step] Warning LLM: {lm_status}")

        return ({"dit_handler": dit_handler, "llm_handler": llm_handler if llm_handler.llm_initialized else None, "active_adapters": {}},)

# ============================================================================
# 2. –ó–∞–≥—Ä—É–∑—á–∏–∫ LoRA
# ============================================================================
class AceStepLoraLoader:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": ("ACESTEP_MODEL",),
                "lora_path": ("STRING", {"default": "", "multiline": False, "placeholder": "–ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ LoRA"}),
                "strength": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 4.0, "step": 0.05}),
                "enable_lora": ("BOOLEAN", {"default": True}),
                "ignore_bias_error": ("BOOLEAN", {"default": True, "tooltip": "–§–∏–ª—å—Ç—Ä—É–µ—Ç bias –∏–∑ –≤–µ—Å–æ–≤ –≤ –ø–∞–º—è—Ç–∏ (–±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞ –¥–∏—Å–∫)"}),
            },
            "optional": {
                 "adapter_name_override": ("STRING", {"default": "", "multiline": False}),
            }
        }

    RETURN_TYPES = ("ACESTEP_MODEL",)
    RETURN_NAMES = ("model",)
    FUNCTION = "load_lora"
    CATEGORY = "ACE-Step"

    def load_lora(self, model, lora_path, strength, enable_lora, ignore_bias_error, adapter_name_override=""):
        if not enable_lora or not lora_path.strip():
            return (model,)

        dit_handler = model["dit_handler"]
        final_path = lora_path.strip()
        
        if not os.path.exists(final_path):
             print(f"[ACE-Step] Warning: LoRA path not found: {final_path}")
             return (model,)

        suffix = "_nb" if ignore_bias_error else ""
        if adapter_name_override.strip():
            adapter_name = adapter_name_override.strip() + suffix
        else:
            path_hash = hashlib.md5(final_path.encode()).hexdigest()[:8]
            base_name = os.path.basename(final_path.rstrip(os.sep)).split('.')[0]
            adapter_name = f"{base_name}_{path_hash}{suffix}"

        load_msg = dit_handler.add_lora(final_path, adapter_name=adapter_name, ignore_bias=ignore_bias_error)

        if "‚ùå" in load_msg and "already loaded" not in load_msg:
            print(f"[ACE-Step] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LoRA {adapter_name}: {load_msg}")
        else:
            print(f"[ACE-Step] LoRA {adapter_name}: OK (weight={strength})")
            new_active = model["active_adapters"].copy()
            new_active[adapter_name] = strength
            
            new_model = model.copy()
            new_model["active_adapters"] = new_active
            return (new_model,)

        return (model,)

# ============================================================================
# 3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ LLM
# ============================================================================
class AceStepLMConfig:
    """
    –£–∑–µ–ª –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, CFG –∏ —Ç.–¥.),
    –∞ —Ç–∞–∫–∂–µ —Å–∏–ª—ã –∞—É–¥–∏–æ-–∫–æ–¥–æ–≤.
    """
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "lm_temperature": ("FLOAT", {"default": 0.85, "min": 0.0, "max": 2.0, "step": 0.05}),
                "lm_cfg_scale": ("FLOAT", {"default": 2.0, "min": 1.0, "max": 5.0, "step": 0.1}),
                "lm_top_p": ("FLOAT", {"default": 0.9, "min": 0.0, "max": 1.0, "step": 0.05}),
                "lm_top_k": ("INT", {"default": 0, "min": 0, "max": 100, "step": 1}),
                "audio_cover_strength": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05, "tooltip": "–°–∏–ª–∞ –∞—É–¥–∏–æ-–∫–æ–¥–æ–≤ / Cover strength"}),
                "lm_negative_prompt": ("STRING", {"default": "NO USER INPUT", "multiline": True}),
            }
        }

    RETURN_TYPES = ("ACESTEP_LM_CONFIG",)
    RETURN_NAMES = ("lm_config",)
    FUNCTION = "create_config"
    CATEGORY = "ACE-Step"

    def create_config(self, lm_temperature, lm_cfg_scale, lm_top_p, lm_top_k, audio_cover_strength, lm_negative_prompt):
        return ({
            "lm_temperature": lm_temperature,
            "lm_cfg_scale": lm_cfg_scale,
            "lm_top_p": lm_top_p,
            "lm_top_k": lm_top_k,
            "audio_cover_strength": audio_cover_strength,
            "lm_negative_prompt": lm_negative_prompt
        },)

# ============================================================================
# 4. –£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM
# ============================================================================
class AceStepPromptEnhancer:
    """
    –ü—Ä–æ–≥–æ–Ω—è–µ—Ç –±–∞–∑–æ–≤—ã–µ caption –∏ lyrics —á–µ—Ä–µ–∑ LLM, 
    –≤–æ–∑–≤—Ä–∞—â–∞—è –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–µ—Å–Ω–∏ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.
    """
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": ("ACESTEP_MODEL",),
                "caption": ("STRING", {"multiline": True, "default": "pop song"}),
                "lyrics": ("STRING", {"multiline": True, "default": ""}),
            },
            "optional": {
                "lm_config": ("ACESTEP_LM_CONFIG",),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "INT", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("enhanced_caption", "enhanced_lyrics", "bpm", "key_scale", "time_signature", "vocal_language")
    FUNCTION = "enhance"
    CATEGORY = "ACE-Step"

    def enhance(self, model, caption, lyrics, lm_config=None):
        llm_handler = model.get("llm_handler")
        if not llm_handler or not getattr(llm_handler, "llm_initialized", False):
            print("[ACE-Step Enhancer] Warning: LLM –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç.")
            return (caption, lyrics, 0, "", "", "unknown")

        temp = 0.85
        top_k = None
        top_p = None

        if lm_config:
            temp = lm_config.get("lm_temperature", 0.85)
            tk = lm_config.get("lm_top_k", 0)
            tp = lm_config.get("lm_top_p", 0.9)
            top_k = tk if tk > 0 else None
            top_p = tp if tp < 1.0 else None

        print("[ACE-Step Enhancer] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM...")
        result = format_sample(
            llm_handler=llm_handler,
            caption=caption,
            lyrics=lyrics,
            user_metadata=None,
            temperature=temp,
            top_k=top_k,
            top_p=top_p,
            use_constrained_decoding=True,
        )

        if not result.success:
            print(f"[ACE-Step Enhancer] –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ –ø—Ä–æ–º–ø—Ç–∞: {result.error or result.status_message}")
            return (caption, lyrics, 0, "", "", "unknown")

        return (
            result.caption or caption,
            result.lyrics or lyrics,
            result.bpm or 0,
            result.keyscale or "",
            result.timesignature or "",
            result.language or "unknown"
        )

# ============================================================================
# 5. –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ú—É–∑—ã–∫–∏
# ============================================================================
class AceStepMusicGenerator:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": ("ACESTEP_MODEL",),
                "task_type": (["text2music", "cover", "repaint"], {"default": "text2music"}),
                "caption": ("STRING", {"multiline": True, "default": "piano solo"}),
                "lyrics": ("STRING", {"multiline": True, "default": "[Instrumental]"}),
                "duration": ("FLOAT", {"default": -1.0, "min": -1.0, "max": 600.0}),
                "inference_steps": ("INT", {"default": 8}),
                "guidance_scale": ("FLOAT", {"default": 7.0}),
                "thinking": ("BOOLEAN", {"default": True}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 0xffffffffffffffff}),
                "unload_unused_loras": ("BOOLEAN", {"default": True}),
            },
            "optional": {
                "reference_audio": ("AUDIO",),
                "source_audio": ("AUDIO",),
                "vocal_language": (["unknown", "en", "zh", "ja", "ru"], {"default": "unknown"}),
                "bpm": ("INT", {"default": 0}),
                "key_scale": ("STRING", {"default": ""}),
                "time_signature": ("STRING", {"default": ""}),
                "lm_config": ("ACESTEP_LM_CONFIG",),
            }
        }

    RETURN_TYPES = ("AUDIO",)
    RETURN_NAMES = ("audio",)
    FUNCTION = "generate"
    CATEGORY = "ACE-Step"

    def _save_comfy_audio_to_temp(self, comfy_audio) -> str:
        if comfy_audio is None: return None
        waveform = comfy_audio["waveform"].squeeze(0)
        sample_rate = comfy_audio["sample_rate"]
        fd, temp_path = tempfile.mkstemp(suffix=".wav")
        os.close(fd)
        torchaudio.save(temp_path, waveform, sample_rate)
        return temp_path

    def _sync_loras(self, dit_handler, requested_adapters, unload_unused):
        if not dit_handler.lora_loaded:
            return

        loaded_adapters = list(dit_handler._active_loras.keys())
        has_active = False
        
        for name in loaded_adapters:
            if name in requested_adapters:
                weight = requested_adapters[name]
                dit_handler.set_lora_scale(name, weight)
                has_active = True
            else:
                if unload_unused:
                    dit_handler.remove_lora(name)
                else:
                    current_weight = dit_handler._active_loras.get(name, 0.0)
                    if current_weight != 0.0:
                        dit_handler.set_lora_scale(name, 0.0)

        if dit_handler.lora_loaded:
            dit_handler.set_use_lora(has_active)

    def generate(self, model, task_type, caption, lyrics, duration, inference_steps, 
                 guidance_scale, thinking, seed, unload_unused_loras, reference_audio=None, source_audio=None, 
                 vocal_language="unknown", bpm=0, key_scale="", time_signature="", lm_config=None):
        
        dit_handler = model["dit_handler"]
        llm_handler = model["llm_handler"]
        active_adapters = model.get("active_adapters", {})

        self._sync_loras(dit_handler, active_adapters, unload_unused_loras)

        if thinking and llm_handler is None:
            thinking = False

        ref_path = self._save_comfy_audio_to_temp(reference_audio)
        src_path = self._save_comfy_audio_to_temp(source_audio)

        lm_temp = 0.85
        lm_cfg = 2.0
        lm_tk = 0
        lm_tp = 0.9
        cover_str = 1.0
        lm_neg_prompt = "NO USER INPUT"

        if lm_config:
            lm_temp = lm_config.get("lm_temperature", 0.85)
            lm_cfg = lm_config.get("lm_cfg_scale", 2.0)
            lm_tk = lm_config.get("lm_top_k", 0)
            lm_tp = lm_config.get("lm_top_p", 0.9)
            cover_str = lm_config.get("audio_cover_strength", 1.0)
            lm_neg_prompt = lm_config.get("lm_negative_prompt", "NO USER INPUT")

        params = GenerationParams(
            task_type=task_type, caption=caption, lyrics=lyrics,
            bpm=bpm if bpm > 0 else None, keyscale=key_scale, timesignature=time_signature,
            duration=duration, vocal_language=vocal_language,
            inference_steps=inference_steps, guidance_scale=guidance_scale, seed=seed,
            thinking=thinking, reference_audio=ref_path,
            src_audio=src_path if task_type != "text2music" else None,
            use_cot_metas=True, use_cot_caption=True, use_cot_language=True,
            audio_cover_strength=cover_str,
            lm_temperature=lm_temp, lm_cfg_scale=lm_cfg, lm_top_k=lm_tk, 
            lm_top_p=lm_tp, lm_negative_prompt=lm_neg_prompt
        )

        config = GenerationConfig(batch_size=1, use_random_seed=(seed == -1), audio_format="wav")

        # ==========================================
        # –ü–†–û–ì–†–ï–°–° –ë–ê–† COMFYUI
        # ==========================================
        pbar = comfy.utils.ProgressBar(100)
        last_percent = 0

        def progress_callback(value, desc=None, *args, **kwargs):
            nonlocal last_percent
            
            # ACE-Step –º–æ–∂–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –ª–∏–±–æ float (0.0 - 1.0), –ª–∏–±–æ —Å—Ç—Ä–æ–∫—É (–∏–Ω—Ñ–æ)
            if isinstance(value, str):
                # print(f"[ACE-Step] {value}")
                return
                
            if isinstance(value, (int, float)):
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º 0.0-1.0 –≤ 0-100
                current_percent = min(100, max(0, int(value * 100)))
                
                # ComfyUI pbar.update() –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –î–ï–õ–¨–¢–£ (—Ä–∞–∑–Ω–∏—Ü—É) —à–∞–≥–æ–≤, –∞ –Ω–µ –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                if current_percent > last_percent:
                    pbar.update(current_percent - last_percent)
                    last_percent = current_percent
                    
            # if desc:
            #     print(f"[ACE-Step Progress] {desc} ({last_percent}%)")

        try:
            # –ü–µ—Ä–µ–¥–∞–µ–º –Ω–∞—à –∫–æ–ª–ª–±—ç–∫ –≤ —è–¥—Ä–æ ACE-Step
            result = generate_music(
                dit_handler=dit_handler, 
                llm_handler=llm_handler, 
                params=params, 
                config=config, 
                save_dir=None,
                progress=progress_callback
            )
            
            if not result.success:
                raise RuntimeError(f"Generation Failed: {result.error}")

            # –î–æ–±–∏–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–æ 100%, –µ—Å–ª–∏ –æ–Ω –Ω–µ –¥–æ—à–µ–ª
            if last_percent < 100:
                pbar.update(100 - last_percent)

            output_audio_tensor = result.audios[0]["tensor"]
            output_sample_rate = result.audios[0]["sample_rate"]

            return ({"waveform": output_audio_tensor.unsqueeze(0), "sample_rate": output_sample_rate},)

        finally:
            if ref_path and os.path.exists(ref_path): os.remove(ref_path)
            if src_path and os.path.exists(src_path): os.remove(src_path)

NODE_CLASS_MAPPINGS = {
    "AceStepModelLoader": AceStepModelLoader,
    "AceStepLoraLoader": AceStepLoraLoader,
    "AceStepLMConfig": AceStepLMConfig,
    "AceStepPromptEnhancer": AceStepPromptEnhancer,
    "AceStepMusicGenerator": AceStepMusicGenerator
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "AceStepModelLoader": "ACE-Step Model Loader üéµ",
    "AceStepLoraLoader": "ACE-Step LoRA Loader üíä",
    "AceStepLMConfig": "ACE-Step LM Config ‚öôÔ∏è",
    "AceStepPromptEnhancer": "ACE-Step Prompt Enhancer ‚úçÔ∏è",
    "AceStepMusicGenerator": "ACE-Step Music Generator üéµ"
}